{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importation des packages et des fonctions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Parmi les packages importés on retrouve :<br>\n",
    "   <ul>\n",
    "       <li>fonctionsUtiles : package qui sert pour l'augmentation des données</li>\n",
    "       <li>matplotlib, numpy : visualisation et manipulation de données</li>\n",
    "       <li>cv2 : pour resize les images et les adapter à l'input du modèle</li> \n",
    "       <li>sklearn : pour la fonction train_test_split</li>\n",
    "       <li>Tensorflow, keras : framework pour deeplearning</li>\n",
    "   </ul>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np \n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fonctionsUtiles import functions as f\n",
    "from fonctionsUtiles import architecture\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from fonctionsUtiles import my_cv as my_cv\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from fonctionsUtiles import error\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args = {\"batch_size\": 30,\n",
    "        \"augmentation\": True,\n",
    "       \"epochs\": 20,\n",
    "       \"val_split\":0.2,\n",
    "       \"early_stop\":True,\n",
    "       \"patience\":2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chargement de toutes les données</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Importation de données recueillies via conduite du véhicule avec la caméra, dans des endroits différents avec un luminosité différente. Présence également de données issues d'un simulateur de données\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data Loaded. Shape =  (26449, 90, 250, 3)\n",
      "Ironcar new track chicane Loaded. Shape =  (1519, 90, 250, 3)\n",
      "Ironcar old track data Loaded. Shape =  (16028, 90, 250, 3)\n",
      "All data loaded and augmented. Shape =  (43996, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Model path\n",
    "model_path = '../Models/'\n",
    "\n",
    "# Get training data from the Axionable track\n",
    "X_axio = np.load('../Datasets/Classification/axionable_data/X_train_axio.npy')\n",
    "Y_axio = np.load('../Datasets/Classification/axionable_data/Y_train_axio.npy')\n",
    "print('Axionable data Loaded. Shape = ', np.shape(X_axio))\n",
    "\n",
    "    \n",
    "# Get training data from IronCar track\n",
    "# New track - Double chicane\n",
    "X_chicane = np.load('../Datasets/Classification/ironcar_data/new_track/x_chicane.npy')\n",
    "Y_chicane = np.load('../Datasets/Classification/ironcar_data/new_track/y_chicane.npy')\n",
    "print('Ironcar new track chicane Loaded. Shape = ', np.shape(X_chicane))\n",
    "\n",
    "\n",
    "# Old track - Balanced dataset\n",
    "X_iron = np.load('../Datasets/Classification/ironcar_data/old_track/balanced_iron_X.npy')\n",
    "Y_iron = np.load('../Datasets/Classification/ironcar_data/old_track/balanced_iron_Y.npy')\n",
    "print('Ironcar old track data Loaded. Shape = ', np.shape(X_iron))\n",
    "\n",
    "    # Concatenate both augmented datasets in a single one\n",
    "Xfinal = np.concatenate((X_axio, X_iron,X_chicane))\n",
    "Yfinal = np.concatenate((Y_axio, Y_iron,Y_chicane))\n",
    "print('All data loaded and augmented. Shape = ', np.shape(Xfinal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    On concatène toutes les données afin de travailler avec un seul vecteur\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xfinal data Loaded. Shape =  (43996, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "del Y_axio, Y_iron,Y_chicane,X_axio, X_iron,X_chicane\n",
    "# On supprime également après toutes les variables temporaires pour libérer de l'espace en mémoire\n",
    "\n",
    "print('Xfinal data Loaded. Shape = ', np.shape(Xfinal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Tri des données utilisables</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Séparation des données en Train, Test et Validation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    On sépare le jeu de données en Training set, Validation set et Testing set selon les proportions suivantes :<br>\n",
    "    <ul>\n",
    "        <li>X_test = 20 % du set Xfinal_resized</li>\n",
    "        <li>X_train = 80 % des données restantes de Xfinal_resized (soit 64 % du jeu total de données)</li>\n",
    "        <li>X_val = 20 % des données restantes de Xfinal_resized (soit 16 % du jeu total de données)</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire qui stock quelques variables importantes\n",
    "args = {\"batch_size\": 30,\n",
    "        \"augmentation\": True,\n",
    "       \"epochs\": 20,\n",
    "       \"val_split\":0.2,\n",
    "       \"early_stop\":True,\n",
    "       \"patience\":2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réparatition du jeu de données en train test 80 - 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xfinal, Yfinal, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition du jeu d'entrainement en jeu d'entrainement et en jeu de validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All training data loaded and augmented. Shape =  (28156, 90, 250, 3)\n",
      "All validation data loaded and augmented. Shape =  (7040, 90, 250, 3)\n",
      "All testing data loaded and augmented. Shape =  (8800, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "print('All training data loaded and augmented. Shape = ', np.shape(X_train))\n",
    "print('All validation data loaded and augmented. Shape = ', np.shape(X_val))\n",
    "print('All testing data loaded and augmented. Shape = ', np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables temporaires qui contiennent les images pour libérer de l'espace mémoire\n",
    "del Xfinal, Yfinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Augmentation des données</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    On augmente les données uniquement sur le jeu d'entrainement pour éviter que le jeu de validation et de test ne contiennent des données que le modèle aurait \"déjà vu\" pendant son entrainement.<br><br>\n",
    "    On rajoute 10% d'image pour chacun des effets suivant :\n",
    "    <ul>\n",
    "        <li>luminosité augmentée</li>\n",
    "        <li>effet de nuit</li>\n",
    "        <li>ombres aléatoires sur la route</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 95/7039 [00:00<00:07, 946.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data... Wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7039/7039 [00:04<00:00, 1657.26it/s]\n",
      "100%|██████████| 7039/7039 [00:02<00:00, 2357.06it/s]\n",
      "100%|██████████| 7039/7039 [00:00<00:00, 352387.22it/s]\n",
      "100%|██████████| 7039/7039 [00:05<00:00, 1331.36it/s]\n",
      "100%|██████████| 7039/7039 [00:09<00:00, 756.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data after augmentation. Shape =  (63351, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation of the dataset / Adjust the proportion of each transformation you want to apply.\n",
    "if args['augmentation']:\n",
    "    print('Augmenting data... Wait...')\n",
    "    # Data augmentation 25% of random brightness.\n",
    "    X_bright, Y_bright = f.generate_brightness(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of night effect.\n",
    "    X_night, Y_night = f.generate_night_effect(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of horizontal flipping.\n",
    "    X_flip, Y_flip = f.generate_horizontal_flip(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of random shadows.\n",
    "    X_shadow, Y_shadow = f.generate_random_shadows(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of chained tranformations (bright + shadows + flip).\n",
    "    X_chain, Y_chain = f.generate_chained_transformations(X_train, Y_train, proportion=0.25)\n",
    "\n",
    "    # Concatenating Axionable dataset with the transformations.\n",
    "    X_train = np.concatenate((X_train, X_bright, X_night,\n",
    "                                X_flip, X_shadow, X_chain))\n",
    "\n",
    "    Y_train = np.concatenate((Y_train, Y_bright, Y_night, \n",
    "                                Y_flip, Y_shadow, Y_chain)).astype('float32')\n",
    "\n",
    "    print('Axionable data after augmentation. Shape = ', np.shape(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables temporaires qui contiennent les images\n",
    "del X_bright, Y_bright, X_night, Y_night, X_shadow, Y_shadow,X_chain,Y_chain,X_flip,Y_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Définition du modèle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    On utilise l'architecture de Nvidia avec la dernière layer pour de la regression\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1210: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_in (InputLayer)          (None, 90, 250, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 43, 123, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 60, 32)        19232     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 28, 64)         51264     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 26, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 24, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flattened (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               614500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "angle_out (Dense)            (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 765,981\n",
      "Trainable params: 765,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "model_path = '../Models/Nvidia/regression_'\n",
    "# Create autopilot model from architectures and print summary\n",
    "model =  architecture.model_categorical(input_size=(90,250,3), dropout=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Schéma du modèle</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(my_new_model, to_file='model.png')\n",
    "\n",
    "# Cela ne fonctionne pas avec les modèles issus de Tensorflow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Entrainement du modèle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    On effectue l'entrainement selon les jeux de données d'entrainement et de validation définis plus haut dans le notebook. On utilise également les hyper paramètres définis auparavant.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63351 samples, validate on 7040 samples\n",
      "Epoch 1/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.4909 - acc: 0.8208Epoch 00000: val_loss improved from inf to 0.13368, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 282s - loss: 0.4908 - acc: 0.8208 - val_loss: 0.1337 - val_acc: 0.9540\n",
      "Epoch 2/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9411Epoch 00001: val_loss improved from 0.13368 to 0.12420, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 281s - loss: 0.1793 - acc: 0.9412 - val_loss: 0.1242 - val_acc: 0.9581\n",
      "Epoch 3/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9557Epoch 00002: val_loss improved from 0.12420 to 0.07164, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 281s - loss: 0.1337 - acc: 0.9557 - val_loss: 0.0716 - val_acc: 0.9773\n",
      "Epoch 4/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9670Epoch 00003: val_loss improved from 0.07164 to 0.06032, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 280s - loss: 0.1022 - acc: 0.9670 - val_loss: 0.0603 - val_acc: 0.9825\n",
      "Epoch 5/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9716Epoch 00004: val_loss improved from 0.06032 to 0.04791, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 281s - loss: 0.0911 - acc: 0.9716 - val_loss: 0.0479 - val_acc: 0.9832\n",
      "Epoch 6/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9746Epoch 00005: val_loss did not improve\n",
      "63351/63351 [==============================] - 280s - loss: 0.0812 - acc: 0.9746 - val_loss: 0.0782 - val_acc: 0.9763\n",
      "Epoch 7/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9779Epoch 00006: val_loss did not improve\n",
      "63351/63351 [==============================] - 280s - loss: 0.0694 - acc: 0.9779 - val_loss: 0.0633 - val_acc: 0.9764\n",
      "Epoch 8/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9792Epoch 00007: val_loss improved from 0.04791 to 0.04392, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 279s - loss: 0.0708 - acc: 0.9792 - val_loss: 0.0439 - val_acc: 0.9848\n",
      "Epoch 9/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9833Epoch 00008: val_loss did not improve\n",
      "63351/63351 [==============================] - 280s - loss: 0.0584 - acc: 0.9833 - val_loss: 0.0514 - val_acc: 0.9861\n",
      "Epoch 10/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9827Epoch 00009: val_loss did not improve\n",
      "63351/63351 [==============================] - 282s - loss: 0.0586 - acc: 0.9827 - val_loss: 0.0469 - val_acc: 0.9851\n",
      "Epoch 11/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9855Epoch 00010: val_loss improved from 0.04392 to 0.03483, saving model to ../Models/normalAugmented.hdf5\n",
      "63351/63351 [==============================] - 282s - loss: 0.0536 - acc: 0.9855 - val_loss: 0.0348 - val_acc: 0.9906\n",
      "Epoch 12/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9845Epoch 00011: val_loss did not improve\n",
      "63351/63351 [==============================] - 282s - loss: 0.0568 - acc: 0.9845 - val_loss: 0.0466 - val_acc: 0.9868\n",
      "Epoch 13/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9875Epoch 00012: val_loss did not improve\n",
      "63351/63351 [==============================] - 282s - loss: 0.0473 - acc: 0.9875 - val_loss: 0.1082 - val_acc: 0.9727\n",
      "Epoch 14/20\n",
      "63330/63351 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9880Epoch 00013: val_loss did not improve\n",
      "63351/63351 [==============================] - 283s - loss: 0.0462 - acc: 0.9880 - val_loss: 0.0630 - val_acc: 0.9837\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model\n",
    "model_name = model_path + 'normalAugmented.hdf5'\n",
    "min_delta=.0005\n",
    "\n",
    "#checkpoint to save model after each epoch\n",
    "save_best = keras.callbacks.ModelCheckpoint(model_name, \n",
    "                                            monitor='val_loss', \n",
    "                                            verbose=1, \n",
    "                                            save_best_only=True, \n",
    "                                            mode='min')\n",
    "#stop training if the validation error stops improving.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                           min_delta=min_delta, \n",
    "                                           patience=args['patience'], \n",
    "                                           verbose=1, \n",
    "                                           mode='auto')\n",
    "callbacks_list = [save_best]\n",
    "\n",
    "if args['early_stop']:\n",
    "    callbacks_list.append(early_stop)\n",
    "    \n",
    "hist = model.fit(\n",
    "                X_train, \n",
    "                Y_train,\n",
    "                nb_epoch=args['epochs'],\n",
    "                batch_size=args['batch_size'], \n",
    "                verbose=1, \n",
    "                validation_data=(X_val, Y_val),\n",
    "                callbacks=callbacks_list,\n",
    "                shuffle=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Temps de prédiction pour une image</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    La cellule suivante utilise une image du jeu de test et calcule le temps qu'il faut pour effectuer la prédiction.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001959562301635742\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "for i in range(1):\n",
    "    model.predict(X_test[i-1:i])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Erreur associée au modèle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Predire sur le testing set et voir l'erreur\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "\n",
    "y_predict[y_predict<0.5]=0\n",
    "y_predict[y_predict>=0.5]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800\n",
      "accuracy forte droite =  0.9773413897280967\n",
      "accuracy droite =  0.9799118079372856\n",
      "accuracy tout droit =  0.9954128440366973\n",
      "accuracy gauche =  0.983739837398374\n",
      "accuracy forte gauche =  0.9662398137369034\n",
      "Accuracy = 0.985\n",
      "Droite =  0.9885312615612283\n",
      "Gauche =  0.9900955076052352\n",
      "Tout Droit =  0.9954128440366973\n",
      "Somme erreur 166.0\n",
      "Erreur moyenne lors erreur  1.2575757575757576\n",
      "Erreur moyenne 0.018863636363636364\n"
     ]
    }
   ],
   "source": [
    "error.error_classification(Y_test,y_predict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
