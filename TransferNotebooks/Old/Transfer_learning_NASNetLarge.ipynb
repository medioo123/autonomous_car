{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importation des packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'fonctionsUtiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0287ee226bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfonctionsUtiles\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfonctionsUtiles\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'fonctionsUtiles'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from fonctionsUtiles import functions as f\n",
    "from fonctionsUtiles import architecture\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.applications import NASNetLarge, InceptionV3\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chargement de toutes les données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data Loaded. Shape =  (26449, 90, 250, 3)\n",
      "Ironcar new track chicane Loaded. Shape =  (1519, 90, 250, 3)\n",
      "Ironcar old track data Loaded. Shape =  (16028, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get training data from the Axionable track\n",
    "X_axio = np.load('../Datasets/axionable_data/X_train_axio.npy')\n",
    "Y_axio = np.load('../Datasets/axionable_data/Y_train_axio.npy')\n",
    "print('Axionable data Loaded. Shape = ', np.shape(X_axio))\n",
    "\n",
    "# Get training data from IronCar track\n",
    "# New track - Double chicane\n",
    "X_chicane = np.load('../Datasets/ironcar_data/new_track/x_chicane.npy')\n",
    "Y_chicane = np.load('../Datasets/ironcar_data/new_track/y_chicane.npy')\n",
    "print('Ironcar new track chicane Loaded. Shape = ', np.shape(X_chicane))\n",
    "\n",
    "# Old track - Balanced dataset\n",
    "X_iron = np.load('../Datasets/ironcar_data/old_track/balanced_iron_X.npy')\n",
    "Y_iron = np.load('../Datasets/ironcar_data/old_track/balanced_iron_Y.npy')\n",
    "print('Ironcar old track data Loaded. Shape = ', np.shape(X_iron))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Resizing des données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data new size. Shape =  (26449, 331, 331, 3)\n",
      "Ironcar new track chicane new size. Shape =  (1519, 331, 331, 3)\n",
      "Ironcar old track data new size. Shape =  (16028, 331, 331, 3)\n"
     ]
    }
   ],
   "source": [
    "def resizing(array):\n",
    "    masterX = list()\n",
    "    for arr in array:\n",
    "        masterX.append(cv2.resize(arr, (331,331)))\n",
    "    return np.array(masterX)\n",
    "\n",
    "X_axio_resized = resizing(X_axio)\n",
    "X_chicane_resized = resizing(X_chicane)\n",
    "X_iron_resized = resizing(X_iron)\n",
    "\n",
    "print('Axionable data new size. Shape = ', np.shape(X_axio_resized))\n",
    "print('Ironcar new track chicane new size. Shape = ', np.shape(X_chicane_resized))\n",
    "print('Ironcar old track data new size. Shape = ', np.shape(X_iron_resized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Séparation des données en Train, Test et Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire qui stock quelques variables importantes\n",
    "args = {\"augmentation\": True,\n",
    "        \"train_split\": 0.8,\n",
    "        \"val_split\":0.2,\n",
    "        \"test_split\":0.2,\n",
    "        \"batch_size\": 200,\n",
    "        \"epochs\": 12,\n",
    "        \"early_stop\":True,\n",
    "        \"patience\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data loaded and concatenated. Shape =  (43996, 331, 331, 3)\n"
     ]
    }
   ],
   "source": [
    "# Concatenation de toutes les données chargées\n",
    "X = np.concatenate((X_axio_resized, X_chicane_resized, X_iron_resized))\n",
    "Y = np.concatenate((Y_axio, Y_chicane, Y_iron))\n",
    "print('All data loaded and concatenated. Shape = ', np.shape(X))\n",
    "\n",
    "# Suppression des variables tmp qui contiennent les images\n",
    "del X_axio, Y_axio, X_chicane, Y_chicane, X_iron, Y_iron, X_axio_resized, X_chicane_resized, X_iron_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réparatition du jeu de données en train test 80 - 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition du jeu d'entrainement en jeu d'entrainement et en jeu de validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All training data loaded and augmented. Shape =  (28156, 331, 331, 3)\n",
      "All validation data loaded and augmented. Shape =  (7040, 331, 331, 3)\n",
      "All testing data loaded and augmented. Shape =  (8800, 331, 331, 3)\n"
     ]
    }
   ],
   "source": [
    "print('All training data loaded and augmented. Shape = ', np.shape(X_train))\n",
    "print('All validation data loaded and augmented. Shape = ', np.shape(X_val))\n",
    "print('All testing data loaded and augmented. Shape = ', np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables tmp qui contiennent les images\n",
    "del X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Augmentation des données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/7039 [00:00<00:29, 239.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data... Wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7039/7039 [00:16<00:00, 437.60it/s]\n",
      "100%|██████████| 7039/7039 [00:12<00:00, 552.43it/s]\n",
      "100%|██████████| 7039/7039 [00:00<00:00, 341326.36it/s]\n",
      "100%|██████████| 7039/7039 [00:19<00:00, 365.40it/s]\n",
      "100%|██████████| 7039/7039 [00:34<00:00, 203.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data after augmentation. Shape =  (63351, 331, 331, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation of the dataset / Adjust the proportion of each transformation you want to apply.\n",
    "if args['augmentation']:\n",
    "    print('Augmenting data... Wait...')\n",
    "    # Data augmentation 25% of random brightness.\n",
    "    X_bright, Y_bright = f.generate_brightness(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of night effect.\n",
    "    X_night, Y_night = f.generate_night_effect(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of horizontal flipping.\n",
    "    X_flip, Y_flip = f.generate_horizontal_flip(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of random shadows.\n",
    "    X_shadow, Y_shadow = f.generate_random_shadows(X_train, Y_train, proportion=0.25)\n",
    "    # Data augmentation 25% of chained tranformations (bright + shadows + flip).\n",
    "    X_chain, Y_chain = f.generate_chained_transformations(X_train, Y_train, proportion=0.25)\n",
    "\n",
    "    # Concatenating Axionable dataset with the transformations.\n",
    "    X_train = np.concatenate((X_train, X_bright, X_night,\n",
    "                                X_flip, X_shadow, X_chain))\n",
    "\n",
    "    Y_train = np.concatenate((Y_train, Y_bright, Y_night, \n",
    "                                Y_flip, Y_shadow, Y_chain)).astype('float32')\n",
    "\n",
    "    print('Axionable data after augmentation. Shape = ', np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables tmp qui contiennent les images\n",
    "del X_bright, Y_bright, X_night, Y_night, X_flip, Y_flip, X_shadow, Y_shadow, X_chain, Y_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Construction du modèle</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de classes en output du modèle. Ici : hard left, left, forward, right et hard right\n",
    "num_classes = 5\n",
    "\n",
    "# Initialisation du modèle : on télécharge le modèle MobilNetV2 et on rajoute la dernière couche\n",
    "# de classification propre à notre problème\n",
    "# my_new_model = Sequential()\n",
    "# my_new_model.add(InceptionV3(include_top=True, pooling='max', weights=\"imagenet\"))\n",
    "# my_new_model.add(Dense(128, activation='relu'))\n",
    "# my_new_model.add(Dropout(0.2))\n",
    "# my_new_model.add(Dense(128, activation='relu'))\n",
    "# my_new_model.add(Dropout(0.2))\n",
    "# my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "l = Dense(128, activation = 'relu')(base_model.output)\n",
    "l = Dropout(0.2)(l)\n",
    "l = Dense(64, activation = 'relu')(l)\n",
    "l = Dropout(0.2)(l)\n",
    "l = Flatten()(l)\n",
    "predictions = Dense(1, activation = 'linear')(l)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# On indique que les couches avant la couche de classification ne doivent pas être entrainées\n",
    "# my_new_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 111, 111, 32) 864         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 111, 111, 32) 96          conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_470 (Activation)     (None, 111, 111, 32) 0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 109, 109, 32) 9216        activation_470[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 109, 109, 32) 96          conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_471 (Activation)     (None, 109, 109, 32) 0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 109, 109, 64) 18432       activation_471[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 109, 109, 64) 192         conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_472 (Activation)     (None, 109, 109, 64) 0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 54, 54, 64)   0           activation_472[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 54, 54, 80)   240         conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_473 (Activation)     (None, 54, 54, 80)   0           batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 52, 52, 192)  138240      activation_473[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, 52, 52, 192)  576         conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_474 (Activation)     (None, 52, 52, 192)  0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 25, 25, 192)  0           activation_474[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, 25, 25, 64)   192         conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_478 (Activation)     (None, 25, 25, 64)   0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 25, 25, 96)   55296       activation_478[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, 25, 25, 48)   144         conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, 25, 25, 96)   288         conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_476 (Activation)     (None, 25, 25, 48)   0           batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_479 (Activation)     (None, 25, 25, 96)   0           batch_normalization_479[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_45 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 25, 25, 64)   76800       activation_476[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 25, 25, 96)   82944       activation_479[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_45[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, 25, 25, 64)   192         conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, 25, 25, 64)   192         conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, 25, 25, 96)   288         conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, 25, 25, 32)   96          conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_475 (Activation)     (None, 25, 25, 64)   0           batch_normalization_475[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_477 (Activation)     (None, 25, 25, 64)   0           batch_normalization_477[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_480 (Activation)     (None, 25, 25, 96)   0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_481 (Activation)     (None, 25, 25, 32)   0           batch_normalization_481[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_475[0][0]             \n",
      "                                                                 activation_477[0][0]             \n",
      "                                                                 activation_480[0][0]             \n",
      "                                                                 activation_481[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, 25, 25, 64)   192         conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, 25, 25, 64)   0           batch_normalization_485[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 25, 25, 96)   55296       activation_485[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchN (None, 25, 25, 48)   144         conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, 25, 25, 96)   288         conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_483 (Activation)     (None, 25, 25, 48)   0           batch_normalization_483[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, 25, 25, 96)   0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_46 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 25, 25, 64)   76800       activation_483[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 25, 25, 96)   82944       activation_486[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchN (None, 25, 25, 64)   192         conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchN (None, 25, 25, 64)   192         conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, 25, 25, 96)   288         conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 25, 25, 64)   192         conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_482 (Activation)     (None, 25, 25, 64)   0           batch_normalization_482[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_484 (Activation)     (None, 25, 25, 64)   0           batch_normalization_484[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, 25, 25, 96)   0           batch_normalization_487[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 25, 25, 64)   0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_482[0][0]             \n",
      "                                                                 activation_484[0][0]             \n",
      "                                                                 activation_487[0][0]             \n",
      "                                                                 activation_488[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 25, 25, 64)   192         conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, 25, 25, 64)   0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 25, 25, 96)   55296       activation_492[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 25, 25, 48)   144         conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, 25, 25, 96)   288         conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, 25, 25, 48)   0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_493 (Activation)     (None, 25, 25, 96)   0           batch_normalization_493[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_47 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 25, 25, 64)   76800       activation_490[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 25, 25, 96)   82944       activation_493[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_47[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 25, 25, 64)   192         conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 25, 25, 64)   192         conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, 25, 25, 96)   288         conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 25, 25, 64)   192         conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 25, 25, 64)   0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, 25, 25, 64)   0           batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_494 (Activation)     (None, 25, 25, 96)   0           batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_495 (Activation)     (None, 25, 25, 64)   0           batch_normalization_495[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_489[0][0]             \n",
      "                                                                 activation_491[0][0]             \n",
      "                                                                 activation_494[0][0]             \n",
      "                                                                 activation_495[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, 25, 25, 64)   192         conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_497 (Activation)     (None, 25, 25, 64)   0           batch_normalization_497[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 25, 25, 96)   55296       activation_497[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, 25, 25, 96)   288         conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_498 (Activation)     (None, 25, 25, 96)   0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 12, 12, 96)   82944       activation_498[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 12, 12, 384)  1152        conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, 12, 12, 96)   288         conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_496 (Activation)     (None, 12, 12, 384)  0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_499 (Activation)     (None, 12, 12, 96)   0           batch_normalization_499[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_496[0][0]             \n",
      "                                                                 activation_499[0][0]             \n",
      "                                                                 max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchN (None, 12, 12, 128)  384         conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_504 (Activation)     (None, 12, 12, 128)  0           batch_normalization_504[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 12, 12, 128)  114688      activation_504[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchN (None, 12, 12, 128)  384         conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_505 (Activation)     (None, 12, 12, 128)  0           batch_normalization_505[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 12, 12, 128)  114688      activation_505[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 12, 12, 128)  384         conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchN (None, 12, 12, 128)  384         conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_501 (Activation)     (None, 12, 12, 128)  0           batch_normalization_501[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_506 (Activation)     (None, 12, 12, 128)  0           batch_normalization_506[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 12, 12, 128)  114688      activation_501[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 12, 12, 128)  114688      activation_506[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchN (None, 12, 12, 128)  384         conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchN (None, 12, 12, 128)  384         conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_502 (Activation)     (None, 12, 12, 128)  0           batch_normalization_502[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_507 (Activation)     (None, 12, 12, 128)  0           batch_normalization_507[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_48 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 12, 12, 192)  172032      activation_502[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 12, 12, 192)  172032      activation_507[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 12, 12, 192)  576         conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchN (None, 12, 12, 192)  576         conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchN (None, 12, 12, 192)  576         conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchN (None, 12, 12, 192)  576         conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_500 (Activation)     (None, 12, 12, 192)  0           batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_503 (Activation)     (None, 12, 12, 192)  0           batch_normalization_503[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_508 (Activation)     (None, 12, 12, 192)  0           batch_normalization_508[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_509 (Activation)     (None, 12, 12, 192)  0           batch_normalization_509[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_500[0][0]             \n",
      "                                                                 activation_503[0][0]             \n",
      "                                                                 activation_508[0][0]             \n",
      "                                                                 activation_509[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchN (None, 12, 12, 160)  480         conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_514 (Activation)     (None, 12, 12, 160)  0           batch_normalization_514[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 12, 12, 160)  179200      activation_514[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchN (None, 12, 12, 160)  480         conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_515 (Activation)     (None, 12, 12, 160)  0           batch_normalization_515[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 12, 12, 160)  179200      activation_515[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchN (None, 12, 12, 160)  480         conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_516 (BatchN (None, 12, 12, 160)  480         conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_511 (Activation)     (None, 12, 12, 160)  0           batch_normalization_511[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_516 (Activation)     (None, 12, 12, 160)  0           batch_normalization_516[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 12, 12, 160)  179200      activation_511[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 12, 12, 160)  179200      activation_516[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchN (None, 12, 12, 160)  480         conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_517 (BatchN (None, 12, 12, 160)  480         conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_512 (Activation)     (None, 12, 12, 160)  0           batch_normalization_512[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_517 (Activation)     (None, 12, 12, 160)  0           batch_normalization_517[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_49 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 12, 12, 192)  215040      activation_512[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 12, 12, 192)  215040      activation_517[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_49[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchN (None, 12, 12, 192)  576         conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchN (None, 12, 12, 192)  576         conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_518 (BatchN (None, 12, 12, 192)  576         conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_519 (BatchN (None, 12, 12, 192)  576         conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_510 (Activation)     (None, 12, 12, 192)  0           batch_normalization_510[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_513 (Activation)     (None, 12, 12, 192)  0           batch_normalization_513[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_518 (Activation)     (None, 12, 12, 192)  0           batch_normalization_518[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_519 (Activation)     (None, 12, 12, 192)  0           batch_normalization_519[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_510[0][0]             \n",
      "                                                                 activation_513[0][0]             \n",
      "                                                                 activation_518[0][0]             \n",
      "                                                                 activation_519[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_524 (BatchN (None, 12, 12, 160)  480         conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_524 (Activation)     (None, 12, 12, 160)  0           batch_normalization_524[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 12, 12, 160)  179200      activation_524[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_525 (BatchN (None, 12, 12, 160)  480         conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_525 (Activation)     (None, 12, 12, 160)  0           batch_normalization_525[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 12, 12, 160)  179200      activation_525[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_521 (BatchN (None, 12, 12, 160)  480         conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_526 (BatchN (None, 12, 12, 160)  480         conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_521 (Activation)     (None, 12, 12, 160)  0           batch_normalization_521[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_526 (Activation)     (None, 12, 12, 160)  0           batch_normalization_526[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 12, 12, 160)  179200      activation_521[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 12, 12, 160)  179200      activation_526[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_522 (BatchN (None, 12, 12, 160)  480         conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_527 (BatchN (None, 12, 12, 160)  480         conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_522 (Activation)     (None, 12, 12, 160)  0           batch_normalization_522[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_527 (Activation)     (None, 12, 12, 160)  0           batch_normalization_527[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_50 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 12, 12, 192)  215040      activation_522[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 12, 12, 192)  215040      activation_527[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_520 (BatchN (None, 12, 12, 192)  576         conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_523 (BatchN (None, 12, 12, 192)  576         conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_528 (BatchN (None, 12, 12, 192)  576         conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_529 (BatchN (None, 12, 12, 192)  576         conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_520 (Activation)     (None, 12, 12, 192)  0           batch_normalization_520[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_523 (Activation)     (None, 12, 12, 192)  0           batch_normalization_523[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_528 (Activation)     (None, 12, 12, 192)  0           batch_normalization_528[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_529 (Activation)     (None, 12, 12, 192)  0           batch_normalization_529[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_520[0][0]             \n",
      "                                                                 activation_523[0][0]             \n",
      "                                                                 activation_528[0][0]             \n",
      "                                                                 activation_529[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_534 (BatchN (None, 12, 12, 192)  576         conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_534 (Activation)     (None, 12, 12, 192)  0           batch_normalization_534[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 12, 12, 192)  258048      activation_534[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_535 (BatchN (None, 12, 12, 192)  576         conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_535 (Activation)     (None, 12, 12, 192)  0           batch_normalization_535[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 12, 12, 192)  258048      activation_535[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_531 (BatchN (None, 12, 12, 192)  576         conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_536 (BatchN (None, 12, 12, 192)  576         conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_531 (Activation)     (None, 12, 12, 192)  0           batch_normalization_531[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_536 (Activation)     (None, 12, 12, 192)  0           batch_normalization_536[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 12, 12, 192)  258048      activation_531[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 12, 12, 192)  258048      activation_536[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_532 (BatchN (None, 12, 12, 192)  576         conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_537 (BatchN (None, 12, 12, 192)  576         conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_532 (Activation)     (None, 12, 12, 192)  0           batch_normalization_532[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_537 (Activation)     (None, 12, 12, 192)  0           batch_normalization_537[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_51 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 12, 12, 192)  258048      activation_532[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 12, 12, 192)  258048      activation_537[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_51[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_530 (BatchN (None, 12, 12, 192)  576         conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_533 (BatchN (None, 12, 12, 192)  576         conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_538 (BatchN (None, 12, 12, 192)  576         conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchN (None, 12, 12, 192)  576         conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_530 (Activation)     (None, 12, 12, 192)  0           batch_normalization_530[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_533 (Activation)     (None, 12, 12, 192)  0           batch_normalization_533[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_538 (Activation)     (None, 12, 12, 192)  0           batch_normalization_538[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_539 (Activation)     (None, 12, 12, 192)  0           batch_normalization_539[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_530[0][0]             \n",
      "                                                                 activation_533[0][0]             \n",
      "                                                                 activation_538[0][0]             \n",
      "                                                                 activation_539[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchN (None, 12, 12, 192)  576         conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_542 (Activation)     (None, 12, 12, 192)  0           batch_normalization_542[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 12, 12, 192)  258048      activation_542[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchN (None, 12, 12, 192)  576         conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_543 (Activation)     (None, 12, 12, 192)  0           batch_normalization_543[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 12, 12, 192)  258048      activation_543[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchN (None, 12, 12, 192)  576         conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchN (None, 12, 12, 192)  576         conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_540 (Activation)     (None, 12, 12, 192)  0           batch_normalization_540[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_544 (Activation)     (None, 12, 12, 192)  0           batch_normalization_544[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 5, 5, 320)    552960      activation_540[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 5, 5, 192)    331776      activation_544[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchN (None, 5, 5, 320)    960         conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_545 (BatchN (None, 5, 5, 192)    576         conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_541 (Activation)     (None, 5, 5, 320)    0           batch_normalization_541[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_545 (Activation)     (None, 5, 5, 192)    0           batch_normalization_545[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_541[0][0]             \n",
      "                                                                 activation_545[0][0]             \n",
      "                                                                 max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_550 (BatchN (None, 5, 5, 448)    1344        conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_550 (Activation)     (None, 5, 5, 448)    0           batch_normalization_550[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 5, 5, 384)    1548288     activation_550[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchN (None, 5, 5, 384)    1152        conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_551 (BatchN (None, 5, 5, 384)    1152        conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_547 (Activation)     (None, 5, 5, 384)    0           batch_normalization_547[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_551 (Activation)     (None, 5, 5, 384)    0           batch_normalization_551[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 5, 5, 384)    442368      activation_547[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 5, 5, 384)    442368      activation_547[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 5, 5, 384)    442368      activation_551[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 5, 5, 384)    442368      activation_551[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_52 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchN (None, 5, 5, 384)    1152        conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchN (None, 5, 5, 384)    1152        conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_552 (BatchN (None, 5, 5, 384)    1152        conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_553 (BatchN (None, 5, 5, 384)    1152        conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchN (None, 5, 5, 320)    960         conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_548 (Activation)     (None, 5, 5, 384)    0           batch_normalization_548[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_549 (Activation)     (None, 5, 5, 384)    0           batch_normalization_549[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_552 (Activation)     (None, 5, 5, 384)    0           batch_normalization_552[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_553 (Activation)     (None, 5, 5, 384)    0           batch_normalization_553[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_554 (BatchN (None, 5, 5, 192)    576         conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_546 (Activation)     (None, 5, 5, 320)    0           batch_normalization_546[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_548[0][0]             \n",
      "                                                                 activation_549[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 5, 5, 768)    0           activation_552[0][0]             \n",
      "                                                                 activation_553[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_554 (Activation)     (None, 5, 5, 192)    0           batch_normalization_554[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_546[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 activation_554[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_559 (BatchN (None, 5, 5, 448)    1344        conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_559 (Activation)     (None, 5, 5, 448)    0           batch_normalization_559[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 5, 5, 384)    1548288     activation_559[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_556 (BatchN (None, 5, 5, 384)    1152        conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_560 (BatchN (None, 5, 5, 384)    1152        conv2d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_556 (Activation)     (None, 5, 5, 384)    0           batch_normalization_556[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_560 (Activation)     (None, 5, 5, 384)    0           batch_normalization_560[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 5, 5, 384)    442368      activation_556[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 5, 5, 384)    442368      activation_556[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 5, 5, 384)    442368      activation_560[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 5, 5, 384)    442368      activation_560[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_53 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_557 (BatchN (None, 5, 5, 384)    1152        conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_558 (BatchN (None, 5, 5, 384)    1152        conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_561 (BatchN (None, 5, 5, 384)    1152        conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_562 (BatchN (None, 5, 5, 384)    1152        conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_53[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_555 (BatchN (None, 5, 5, 320)    960         conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_557 (Activation)     (None, 5, 5, 384)    0           batch_normalization_557[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_558 (Activation)     (None, 5, 5, 384)    0           batch_normalization_558[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_561 (Activation)     (None, 5, 5, 384)    0           batch_normalization_561[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_562 (Activation)     (None, 5, 5, 384)    0           batch_normalization_562[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_563 (BatchN (None, 5, 5, 192)    576         conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_555 (Activation)     (None, 5, 5, 320)    0           batch_normalization_555[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_557[0][0]             \n",
      "                                                                 activation_558[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 5, 5, 768)    0           activation_561[0][0]             \n",
      "                                                                 activation_562[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_563 (Activation)     (None, 5, 5, 192)    0           batch_normalization_563[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_555[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 activation_563[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 5, 5, 128)    262272      mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 5, 128)    0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5, 5, 64)     8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 5, 5, 64)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            1601        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,074,913\n",
      "Trainable params: 22,040,481\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "# On vérfie la structure du modèle\n",
    "model.summary()\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit la fonction d'optimisation du modèle\n",
    "my_new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0617 17:30:31.790341 139796909606656 training.py:618] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63351 samples, validate on 7040 samples\n",
      "Epoch 1/12\n",
      "  400/63351 [..............................] - ETA: 5:08:55 - loss: 8.2947 - acc: 0.2800"
     ]
    }
   ],
   "source": [
    "# Paramètre de réduction du learning rate si l'accuracy en validation diminue\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', \n",
    "                              factor=0.2,\n",
    "                              patience=5, \n",
    "                              min_lr=0.001)\n",
    "\n",
    "hist = my_new_model.fit(\n",
    "                X_train, \n",
    "                Y_train,\n",
    "                nb_epoch= args['epochs'],\n",
    "                batch_size=args['batch_size'], \n",
    "                verbose=1, \n",
    "                validation_data=(X_val, Y_val),\n",
    "                shuffle=True, \n",
    "                callbacks = [reduce_lr])\n",
    "\n",
    "my_new_model.save('TransferNASNetLarge_12Epochs_doubledenselayer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
