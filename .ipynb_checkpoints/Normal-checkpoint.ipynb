{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervisedCar import functions\n",
    "from supervisedCar import architecture\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args = {\"batch_size\": 200,\n",
    "        \"augmentation\": True,\n",
    "       \"epochs\": 2,\n",
    "       \"val_split\":0.2,\n",
    "       \"early_stop\":True,\n",
    "       \"patience\":2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data Loaded. Shape =  (26449, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Model path\n",
    "model_path = 'Models/'\n",
    "\n",
    "# Get training data from the Axionable track\n",
    "X_axio = np.load('Datasets/axionable_data/X_train_axio.npy')\n",
    "Y_axio = np.load('Datasets/axionable_data/Y_train_axio.npy')\n",
    "print('Axionable data Loaded. Shape = ', np.shape(X_axio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 282/6612 [00:00<00:02, 2811.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data... Wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6612/6612 [00:02<00:00, 2701.32it/s]\n",
      "100%|██████████| 6612/6612 [00:01<00:00, 4328.66it/s]\n",
      "100%|██████████| 6612/6612 [00:00<00:00, 595276.42it/s]\n",
      "100%|██████████| 6612/6612 [00:02<00:00, 2643.71it/s]\n",
      "100%|██████████| 6612/6612 [00:04<00:00, 1359.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axionable data after augmentation. Shape =  (59509, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation of the dataset / Adjust the proportion of each transformation you want to apply.\n",
    "if args['augmentation']:\n",
    "    print('Augmenting data... Wait...')\n",
    "    # Data augmentation 25% of random brightness.\n",
    "    X_bright, Y_bright = generate_brightness(X_axio, Y_axio, proportion=0.25)\n",
    "    # Data augmentation 25% of night effect.\n",
    "    X_night, Y_night = generate_night_effect(X_axio, Y_axio, proportion=0.25)\n",
    "    # Data augmentation 25% of horizontal flipping.\n",
    "    X_flip, Y_flip = generate_horizontal_flip(X_axio, Y_axio, proportion=0.25)\n",
    "    # Data augmentation 25% of random shadows.\n",
    "    X_shadow, Y_shadow = generate_random_shadows(X_axio, Y_axio, proportion=0.25)\n",
    "    # Data augmentation 25% of chained tranformations (bright + shadows + flip).\n",
    "    X_chain, Y_chain = generate_chained_transformations(X_axio, Y_axio, proportion=0.25)\n",
    "\n",
    "    # Concatenating Axionable dataset with the transformations.\n",
    "    X_axio = np.concatenate((X_axio, X_bright, X_night,\n",
    "                                X_flip, X_shadow, X_chain))\n",
    "\n",
    "    Y_axio = np.concatenate((Y_axio, Y_bright, Y_night, \n",
    "                                Y_flip, Y_shadow, Y_chain)).astype('float32')\n",
    "\n",
    "    print('Axionable data after augmentation. Shape = ', np.shape(X_axio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironcar new track chicane Loaded. Shape =  (1519, 90, 250, 3)\n",
      "Ironcar old track data Loaded. Shape =  (16028, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get training data from IronCar track\n",
    "# New track - Double chicane\n",
    "X_chicane = np.load('Datasets/ironcar_data/new_track/x_chicane.npy')\n",
    "Y_chicane = np.load('Datasets/ironcar_data/new_track/y_chicane.npy')\n",
    "print('Ironcar new track chicane Loaded. Shape = ', np.shape(X_chicane))\n",
    "\n",
    "# Old track - Balanced dataset\n",
    "X_iron = np.load('Datasets/ironcar_data/old_track/balanced_iron_X.npy')\n",
    "Y_iron = np.load('Datasets/ironcar_data/old_track/balanced_iron_Y.npy')\n",
    "print('Ironcar old track data Loaded. Shape = ', np.shape(X_iron))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 277/1519 [00:00<00:00, 2765.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data... Wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1519/1519 [00:00<00:00, 2812.40it/s]\n",
      "100%|██████████| 4007/4007 [00:01<00:00, 2828.73it/s]\n",
      "100%|██████████| 4007/4007 [00:01<00:00, 2294.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironcar data after augmentation. Shape =  (25561, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "if args['augmentation']:\n",
    "    print('Augmenting data... Wait...')\n",
    "    # Augmentation of the \"Double Chicane\" Proportion=1. Duplicate the original data (aprox 1500 images)\n",
    "    X_chicane_aug, Y_chicane_aug = generate_brightness(X_chicane, Y_chicane, proportion=1)\n",
    "    # Irocar Balanced Dataset\n",
    "    # 25% of random bright transformations \n",
    "    X_bright_iron, Y_bright_iron = generate_brightness(X_iron, Y_iron, proportion=0.25)\n",
    "    # 25% of lo gamma transformations (darker images)\n",
    "    X_gamma_iron, Y_gamma_iron = generate_low_gamma(X_iron, Y_iron, proportion=0.25, min_=0.7, max_=0.8)\n",
    "\n",
    "    # Concatenating IronCar dataset with the transformations.\n",
    "    X_iron = np.concatenate((X_iron, X_chicane_aug, \n",
    "                                   X_bright_iron,X_gamma_iron))\n",
    "\n",
    "    Y_iron = np.concatenate((Y_iron, Y_chicane_aug, \n",
    "                                   Y_bright_iron, Y_gamma_iron)).astype('float32')\n",
    "\n",
    "    print('Ironcar data after augmentation. Shape = ', np.shape(X_iron))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data loaded and augmented. Shape =  (85070, 90, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate both augmented datasets in a single one\n",
    "X = np.concatenate((X_axio, X_iron))\n",
    "Y = np.concatenate((Y_axio, Y_iron))\n",
    "print('All data loaded and augmented. Shape = ', np.shape(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train/validation split. We do not use test set.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=args['val_split'], random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_in (InputLayer)          (None, 90, 250, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 43, 123, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 20, 60, 32)        19232     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 28, 64)         51264     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 26, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 24, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flattened (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               614500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "angle_out (Dense)            (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 765,981\n",
      "Trainable params: 765,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create autopilot model from architectures and print summary\n",
    "model =  architecture.model_categorical(input_size=(90,250,3), dropout=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model_name = model_path + 'first.hdf5'\n",
    "min_delta=.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint to save model after each epoch\n",
    "save_best = keras.callbacks.ModelCheckpoint(model_name, \n",
    "                                            monitor='val_loss', \n",
    "                                            verbose=1, \n",
    "                                            save_best_only=True, \n",
    "                                            mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop training if the validation error stops improving.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                           min_delta=min_delta, \n",
    "                                           patience=args['patience'], \n",
    "                                           verbose=1, \n",
    "                                           mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [save_best]\n",
    "\n",
    "if args['early_stop']:\n",
    "    callbacks_list.append(early_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68056 samples, validate on 17014 samples\n",
      "Epoch 1/2\n",
      "68056/68056 [==============================] - 285s 4ms/step - loss: 0.7077 - acc: 0.7480 - val_loss: 0.2000 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20000, saving model to Models/first.hdf5\n",
      "Epoch 2/2\n",
      "68056/68056 [==============================] - 285s 4ms/step - loss: 0.1624 - acc: 0.9476 - val_loss: 0.0990 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20000 to 0.09898, saving model to Models/first.hdf5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "                X_train, \n",
    "                Y_train,\n",
    "                nb_epoch=args['epochs'],\n",
    "                batch_size=args['batch_size'], \n",
    "                verbose=1, \n",
    "                validation_data=(X_val, Y_val),\n",
    "                callbacks=callbacks_list,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X[4000:])\n",
    "y_test=Y[4000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred<0.5]=0\n",
    "y_pred[y_pred>=0.5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78661\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "for i in range(len(y_pred)):\n",
    "    if str(y_test[i])==str(y_pred[i]):\n",
    "            s=s+1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702849389416554"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78661/(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "\n",
    "model.predict(X[:1])\n",
    "\n",
    "print(time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
